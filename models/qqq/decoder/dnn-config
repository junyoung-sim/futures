{"layer_config": [[25, 25], [25, 100], [100, 75]], "activation": "relu", "abs_synapse": 1.0, "cost": "MSE", "learning_rate": 0.01}